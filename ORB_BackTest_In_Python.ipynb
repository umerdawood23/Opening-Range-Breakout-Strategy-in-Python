{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Global Parameters & Imports\n",
        "# ================================\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib.ticker as mticker\n",
        "import pytz\n",
        "import math\n",
        "import time\n",
        "import yfinance as yf\n",
        "from datetime import datetime, timedelta\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# ===== Configuration =====\n",
        "TICKER = \"TQQQ\"\n",
        "START_DATE = \"2016-01-01\"\n",
        "END_DATE = \"2023-02-17\"\n",
        "OUTPUT_FILE = f\"{TICKER}_unadjusted.csv\"\n",
        "\n",
        "utc_tz = pytz.timezone('UTC')\n",
        "nyc_tz = pytz.timezone('America/New_York')\n",
        "\n",
        "# ================================\n",
        "# Data Download Functions (Yahoo Finance)\n",
        "# ================================\n",
        "# ================================\n",
        "# Modified Data Download Function\n",
        "# ================================\n",
        "def get_yfinance_data(ticker=TICKER, start_date=START_DATE, end_date=END_DATE):\n",
        "    \"\"\"Fetch intraday data from Yahoo Finance with automatic interval adjustment.\"\"\"\n",
        "    print(f\"Downloading {ticker} data from {start_date} to {end_date}...\")\n",
        "\n",
        "    # Determine if we need both 1m and 5m data\n",
        "    end_dt = datetime.strptime(end_date, '%Y-%m-%d')\n",
        "    cutoff_date = datetime.now() - timedelta(days=30)\n",
        "\n",
        "    if end_dt <= cutoff_date:\n",
        "        # Entire range is older than 30 days - use 5m data\n",
        "        print(\"Using 5m data for full historical range\")\n",
        "        return get_yfinance_chunked(ticker, start_date, end_date, \"5m\")\n",
        "    elif datetime.strptime(start_date, '%Y-%m-%d') >= cutoff_date:\n",
        "        # Entire range is within last 30 days - use 1m data\n",
        "        print(\"Using 1m data for recent range\")\n",
        "        return get_yfinance_chunked(ticker, start_date, end_date, \"1m\")\n",
        "    else:\n",
        "        # Need to combine 5m (historical) and 1m (recent) data\n",
        "        print(\"Combining 5m (historical) and 1m (recent) data\")\n",
        "        historical = get_yfinance_chunked(ticker, start_date, cutoff_date.strftime('%Y-%m-%d'), \"5m\")\n",
        "        recent = get_yfinance_chunked(ticker, cutoff_date.strftime('%Y-%m-%d'), end_date, \"1m\")\n",
        "        return pd.concat([historical, recent]).sort_index()\n",
        "\n",
        "def get_yfinance_chunked(ticker, start_date, end_date, interval):\n",
        "    \"\"\"Fetch data in chunks to handle Yahoo limitations.\"\"\"\n",
        "    data_chunks = []\n",
        "    current_start = datetime.strptime(start_date, '%Y-%m-%d')\n",
        "    end_dt = datetime.strptime(end_date, '%Y-%m-%d')\n",
        "    chunk_size = timedelta(days=7) if interval == \"1m\" else timedelta(days=59)\n",
        "\n",
        "    while current_start < end_dt:\n",
        "        current_end = min(current_start + chunk_size, end_dt)\n",
        "        print(f\"Fetching {interval} data for {current_start.date()} to {current_end.date()}...\")\n",
        "\n",
        "        try:\n",
        "            chunk = yf.download(\n",
        "                tickers=ticker,\n",
        "                start=current_start,\n",
        "                end=current_end,\n",
        "                interval=interval,\n",
        "                progress=False,\n",
        "                auto_adjust=False\n",
        "            )\n",
        "            if not chunk.empty:\n",
        "                data_chunks.append(chunk)\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching {current_start} to {current_end}: {str(e)}\")\n",
        "\n",
        "        current_start = current_end + timedelta(days=1)\n",
        "        time.sleep(1)  # Rate limiting\n",
        "\n",
        "    return pd.concat(data_chunks).sort_index() if data_chunks else pd.DataFrame()\n",
        "\n",
        "# ================================\n",
        "# Update the download_and_merge_data function\n",
        "# ================================\n",
        "def download_and_merge_data():\n",
        "    \"\"\"Download and merge intraday and daily data using Yahoo Finance.\"\"\"\n",
        "    # Get daily data for ATR\n",
        "    daily_data = get_daily_adjusted_data()\n",
        "    if daily_data.empty:\n",
        "        print(\"Unable to get daily data. Exiting.\")\n",
        "        return None\n",
        "\n",
        "    # Get intraday data (automatically handles 1m/5m selection)\n",
        "    print(f\"Downloading intraday data for {TICKER} from {START_DATE}...\")\n",
        "    intraday_data = get_yfinance_data()\n",
        "\n",
        "    if intraday_data.empty:\n",
        "        print(\"No intraday data found.\")\n",
        "        return None\n",
        "\n",
        "    # Process and merge\n",
        "    final_df = process_data(intraday_data)\n",
        "    if not final_df.empty:\n",
        "        final_df = pd.merge(final_df, daily_data, on='day', how='left')\n",
        "        final_df['caldt'] += pd.Timedelta(minutes=1)\n",
        "        cols = ['caldt', 'open', 'high', 'low', 'close', 'volume', 'day', 'dOpen', 'ATR']\n",
        "        final_df[cols].to_csv(OUTPUT_FILE, index=False)\n",
        "        print(f\"Data saved to {OUTPUT_FILE}\")\n",
        "        print(f\"Total records: {len(final_df)}\")\n",
        "        return final_df\n",
        "    else:\n",
        "        print(\"No data after processing.\")\n",
        "        return None\n",
        "\n",
        "# The rest of your code remains the same...\n",
        "\n",
        "# ================================\n",
        "# Performance Analysis & Backtesting Functions\n",
        "# ================================\n",
        "def price2return(price, n=1):\n",
        "    \"\"\"Convert a series of prices into returns.\"\"\"\n",
        "    price = np.array(price)\n",
        "    T = len(price)\n",
        "    y = np.full_like(price, np.nan, dtype=float)\n",
        "    if T > n:\n",
        "        y[n:] = price[n:] / price[:T-n] - 1\n",
        "    return y\n",
        "\n",
        "def summary_statistics(dailyReturns):\n",
        "    \"\"\"Calculate performance metrics and return a summary table.\"\"\"\n",
        "    riskFreeRate = 0\n",
        "    tradingDays = 252\n",
        "    dailyReturns = np.array(dailyReturns)\n",
        "    dailyReturns = dailyReturns[~np.isnan(dailyReturns)]\n",
        "    totalReturn = np.prod(1 + dailyReturns) - 1\n",
        "    numYears = len(dailyReturns) / tradingDays\n",
        "    CAGR = (1 + totalReturn)**(1/numYears) - 1\n",
        "    volatility = np.std(dailyReturns, ddof=0) * np.sqrt(tradingDays)\n",
        "    sharpeRatio = (np.mean(dailyReturns) - riskFreeRate/tradingDays) / np.std(dailyReturns, ddof=0) * np.sqrt(tradingDays)\n",
        "    nav = np.cumprod(1 + dailyReturns)\n",
        "    peak = np.maximum.accumulate(nav)\n",
        "    drawdown = (nav - peak) / peak\n",
        "    MDD = np.min(drawdown)\n",
        "    metrics = [\"Total Return (%)\", \"CAGR (%)\", \"Volatility (%)\", \"Sharpe Ratio\", \"Max Drawdown (%)\"]\n",
        "    values = [totalReturn*100, CAGR*100, volatility*100, sharpeRatio, MDD*100]\n",
        "    formatted_values = [f\"{v:.4f}\" if i < 3 or i == 4 else f\"{v:.6f}\" for i,v in enumerate(values)]\n",
        "    performance_table = pd.DataFrame({'Metric': metrics, 'Value': formatted_values})\n",
        "    return performance_table\n",
        "\n",
        "def monthly_performance_table(returns, dates):\n",
        "    \"\"\"Create a table of monthly returns.\"\"\"\n",
        "    returns_series = pd.Series(returns, index=pd.DatetimeIndex(dates))\n",
        "    returns_series = returns_series[~np.isnan(returns_series)]\n",
        "    df = pd.DataFrame({'return': returns_series,\n",
        "                       'year': returns_series.index.year,\n",
        "                       'month': returns_series.index.month})\n",
        "    monthly_returns = df.groupby(['year', 'month'])['return'].apply(lambda x: np.prod(1 + x) - 1).reset_index()\n",
        "    pivot_table = monthly_returns.pivot(index='year', columns='month', values='return')\n",
        "    pivot_table['Year Total'] = pivot_table.apply(lambda row: np.prod(1 + row.dropna()) - 1\n",
        "                                                   if not row.dropna().empty else np.nan, axis=1)\n",
        "    formatted_table = pivot_table.apply(lambda col: col.map(lambda x: f\"{x*100:.2f}%\" if not pd.isna(x) else \"\"))\n",
        "    month_names = {1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun',\n",
        "                   7: 'Jul', 8: 'Aug', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dec'}\n",
        "    formatted_table = formatted_table.rename(columns=month_names)\n",
        "    return formatted_table\n",
        "\n",
        "def backtest(days, p, orb_m, target_R, risk, max_Lev, AUM_0, commission):\n",
        "    \"\"\"Perform an optimized backtest for the ORB strategy.\"\"\"\n",
        "    start_time = time.time()\n",
        "    str_df = pd.DataFrame()\n",
        "    str_df['Date'] = days\n",
        "    str_df['AUM'] = np.nan\n",
        "    str_df.loc[0, 'AUM'] = AUM_0\n",
        "    str_df['pnl_R'] = np.nan\n",
        "    or_candles = orb_m\n",
        "    day_groups = dict(tuple(p.groupby(p['day'].dt.date)))\n",
        "    trade_id = 0\n",
        "    trade_log = []\n",
        "\n",
        "    for t in range(1, len(days)):\n",
        "        current_day = days[t].date()\n",
        "        if current_day not in day_groups:\n",
        "            str_df.loc[t, 'pnl_R'] = 0\n",
        "            str_df.loc[t, 'AUM'] = str_df.loc[t-1, 'AUM']\n",
        "            continue\n",
        "\n",
        "        day_data = day_groups[current_day]\n",
        "        if len(day_data) <= or_candles:\n",
        "            str_df.loc[t, 'pnl_R'] = 0\n",
        "            str_df.loc[t, 'AUM'] = str_df.loc[t-1, 'AUM']\n",
        "            continue\n",
        "\n",
        "        OHLC = day_data[['open', 'high', 'low', 'close']].values\n",
        "        split_adj = OHLC[0, 0] / day_data['dOpen'].iloc[0]\n",
        "        atr_raw = day_data['ATR'].iloc[0] * split_adj\n",
        "        side = np.sign(OHLC[or_candles-1, 3] - OHLC[0, 0])\n",
        "        entry = OHLC[or_candles, 0] if len(OHLC) > or_candles else np.nan\n",
        "\n",
        "        if side == 1:\n",
        "            stop = abs(np.min(OHLC[:or_candles, 2]) / entry - 1)\n",
        "        elif side == -1:\n",
        "            stop = abs(np.max(OHLC[:or_candles, 1]) / entry - 1)\n",
        "        else:\n",
        "            stop = np.nan\n",
        "\n",
        "        if side == 0 or math.isnan(stop) or math.isnan(entry):\n",
        "            str_df.loc[t, 'pnl_R'] = 0\n",
        "            str_df.loc[t, 'AUM'] = str_df.loc[t-1, 'AUM']\n",
        "            continue\n",
        "\n",
        "        if entry == 0 or stop == 0:\n",
        "            shares = 0\n",
        "        else:\n",
        "            shares = math.floor(min(str_df.loc[t-1, 'AUM'] * risk / (entry * stop),\n",
        "                                    max_Lev * str_df.loc[t-1, 'AUM'] / entry))\n",
        "\n",
        "        if shares == 0:\n",
        "            str_df.loc[t, 'pnl_R'] = 0\n",
        "            str_df.loc[t, 'AUM'] = str_df.loc[t-1, 'AUM']\n",
        "            continue\n",
        "\n",
        "        OHLC_post_entry = OHLC[or_candles:, :]\n",
        "\n",
        "        exit_reason = None\n",
        "        exit_idx    = None\n",
        "        exit_price  = None\n",
        "\n",
        "        if side == 1:  # Long trade\n",
        "            stop_price   = entry * (1 - stop)\n",
        "            target_price = entry * (1 + target_R * stop) if np.isfinite(target_R) else float('inf')\n",
        "\n",
        "            stop_hits   = OHLC_post_entry[:, 2] <= stop_price\n",
        "            target_hits = OHLC_post_entry[:, 1]  > target_price\n",
        "\n",
        "            if np.any(stop_hits) and np.any(target_hits):\n",
        "                idx_stop, idx_target = np.argmax(stop_hits), np.argmax(target_hits)\n",
        "                if idx_target < idx_stop:\n",
        "                    exit_idx   = idx_target\n",
        "                    exit_price = max(target_price, OHLC_post_entry[idx_target, 0])\n",
        "                    exit_reason = 'Target'\n",
        "                else:\n",
        "                    exit_idx   = idx_stop\n",
        "                    exit_price = min(stop_price, OHLC_post_entry[idx_stop, 0])\n",
        "                    exit_reason = 'Stop'\n",
        "            elif np.any(stop_hits):\n",
        "                exit_idx   = np.argmax(stop_hits)\n",
        "                exit_price = min(stop_price, OHLC_post_entry[exit_idx, 0])\n",
        "                exit_reason = 'Stop'\n",
        "            elif np.any(target_hits):\n",
        "                exit_idx   = np.argmax(target_hits)\n",
        "                exit_price = max(target_price, OHLC_post_entry[exit_idx, 0])\n",
        "                exit_reason = 'Target'\n",
        "            else:  # EOD exit\n",
        "                exit_idx   = -1\n",
        "                exit_price = OHLC_post_entry[-1, 3]\n",
        "                exit_reason = 'Close'\n",
        "\n",
        "            PnL_T = exit_price - entry\n",
        "\n",
        "        elif side == -1:  # Short trade\n",
        "            stop_price   = entry * (1 + stop)\n",
        "            target_price = entry * (1 - target_R * stop) if np.isfinite(target_R) else 0\n",
        "\n",
        "            stop_hits   = OHLC_post_entry[:, 1] >= stop_price\n",
        "            target_hits = OHLC_post_entry[:, 2]  < target_price\n",
        "\n",
        "            if np.any(stop_hits) and np.any(target_hits):\n",
        "                idx_stop, idx_target = np.argmax(stop_hits), np.argmax(target_hits)\n",
        "                if idx_target < idx_stop:\n",
        "                    exit_idx   = idx_target\n",
        "                    exit_price = min(target_price, OHLC_post_entry[idx_target, 0])\n",
        "                    exit_reason = 'Target'\n",
        "                else:\n",
        "                    exit_idx   = idx_stop\n",
        "                    exit_price = max(stop_price, OHLC_post_entry[idx_stop, 0])\n",
        "                    exit_reason = 'Stop'\n",
        "            elif np.any(stop_hits):\n",
        "                exit_idx   = np.argmax(stop_hits)\n",
        "                exit_price = max(stop_price, OHLC_post_entry[exit_idx, 0])\n",
        "                exit_reason = 'Stop'\n",
        "            elif np.any(target_hits):\n",
        "                exit_idx   = np.argmax(target_hits)\n",
        "                exit_price = min(target_price, OHLC_post_entry[exit_idx, 0])\n",
        "                exit_reason = 'Target'\n",
        "            else:  # EOD exit\n",
        "                exit_idx   = -1\n",
        "                exit_price = OHLC_post_entry[-1, 3]\n",
        "                exit_reason = 'Close'\n",
        "\n",
        "            PnL_T = entry - exit_price\n",
        "\n",
        "        str_df.loc[t, 'AUM'] = str_df.loc[t-1, 'AUM'] + shares * PnL_T - shares * commission * 2\n",
        "        str_df.loc[t, 'pnl_R'] = (str_df.loc[t, 'AUM'] - str_df.loc[t-1, 'AUM']) / (risk * str_df.loc[t-1, 'AUM'])\n",
        "\n",
        "        entry_ts = day_data['caldt'].iloc[or_candles]\n",
        "        exit_ts  = day_data['caldt'].iloc[or_candles + exit_idx]\n",
        "\n",
        "        trade_id += 1\n",
        "        trade_log.append({\n",
        "            'TradeID'     : trade_id,\n",
        "            'Date'        : current_day,\n",
        "            'Side'        : 'Long' if side == 1 else 'Short',\n",
        "            'EntryTime'   : entry_ts,\n",
        "            'EntryPx'     : entry,\n",
        "            'StopPx'      : stop_price,\n",
        "            'TargetPx'    : target_price if np.isfinite(target_R) else np.nan,\n",
        "            'ExitTime'    : exit_ts,\n",
        "            'ExitPx'      : exit_price,\n",
        "            'ExitReason'  : exit_reason,\n",
        "            'Shares'      : shares,\n",
        "            'PnL_$'       : shares * PnL_T,\n",
        "            'PnL_R'       : (shares * PnL_T) / (risk * str_df.loc[t-1, 'AUM']),\n",
        "            'AUM_After'   : str_df.loc[t, 'AUM']\n",
        "        })\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"******** Optimized Backtest Completed in {round(end_time - start_time, 2)} seconds! ********\")\n",
        "    print(f\"Starting AUM: ${AUM_0:,.2f}\")\n",
        "    print(f\"Final AUM: ${str_df['AUM'].iloc[-1]:,.2f}\")\n",
        "    print(f\"Total Return: {(str_df['AUM'].iloc[-1]/AUM_0 - 1)*100:.4f}%\")\n",
        "\n",
        "    trades_df = pd.DataFrame(trade_log)\n",
        "\n",
        "    return str_df, trades_df\n",
        "\n",
        "def plot_equity_curve(str_df, AUM_0, orb_m, target_R, ticker):\n",
        "    \"\"\"Plot the equity curve with weekly resampling and highlight out-of-sample period.\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(12, 7))\n",
        "    df_plot = str_df.copy()\n",
        "    if 'Date' in df_plot.columns:\n",
        "        df_plot = df_plot.set_index('Date')\n",
        "    try:\n",
        "        weekly_data = df_plot['AUM'].resample('W').last().dropna()\n",
        "    except Exception as e:\n",
        "        print(\"Resampling failed, using original data.\", e)\n",
        "        weekly_data = df_plot['AUM'].dropna()\n",
        "\n",
        "    p1, = ax.plot(weekly_data.index, weekly_data.values, 'r-', linewidth=2, label='Equity')\n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %y'))\n",
        "    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
        "    plt.xticks(rotation=90)\n",
        "    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'${x:,.0f}'))\n",
        "    ax.grid(True, linestyle=':')\n",
        "\n",
        "    min_val = weekly_data.min() if not weekly_data.empty else AUM_0\n",
        "    max_val = weekly_data.max() if not weekly_data.empty else AUM_0\n",
        "    ax.set_ylim([0.9 * min_val, 1.25 * max_val])\n",
        "\n",
        "    target_str = f\"Target {target_R}R\" if np.isfinite(target_R) else \"No Target\"\n",
        "    ax.set_title(f\"{orb_m}m-ORB - Stop @ OR High/Low - {target_str}\\nFull Period - Ticker = {ticker}\", fontsize=12)\n",
        "\n",
        "    # Highlight out-of-sample period starting from a specific date\n",
        "    start_date = datetime(2023, 2, 17)\n",
        "    if not weekly_data.empty and start_date >= weekly_data.index[0] and start_date <= weekly_data.index[-1]:\n",
        "        p2 = ax.axvspan(start_date, weekly_data.index[-1], alpha=0.1, color='green', label='Out-of-Sample')\n",
        "        ax.legend(handles=[p1, p2], loc='upper left')\n",
        "    else:\n",
        "        ax.legend(loc='upper left')\n",
        "\n",
        "    ax.set_yscale('log')\n",
        "    ax.yaxis.set_major_locator(mticker.LogLocator(base=10.0, subs=None))\n",
        "    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'${x:,.0f}'))\n",
        "    return fig, ax\n",
        "\n",
        "# ================================\n",
        "# Main Execution\n",
        "# ================================\n",
        "if __name__ == \"__main__\":\n",
        "    # Download & merge data\n",
        "    data = download_and_merge_data()\n",
        "    if data is None:\n",
        "        raise Exception(\"Data download failed.\")\n",
        "\n",
        "    # Load the exported intraday data\n",
        "    p = pd.read_csv(OUTPUT_FILE, parse_dates=['caldt', 'day'])\n",
        "    days = pd.to_datetime(p['day'].unique())\n",
        "    days = pd.DatetimeIndex(sorted(days))\n",
        "\n",
        "    # Backtest parameters\n",
        "    orb_m = 5             # Opening Range (minutes)\n",
        "    target_R = float('inf')  # Profit target (use inf for no target)\n",
        "    commission = 0.0005   # Commission per share\n",
        "    risk = 0.01           # Equity risk per trade (1% of AUM)\n",
        "    max_Lev = 4           # Maximum leverage\n",
        "    AUM_0 = 25000         # Starting capital\n",
        "\n",
        "    # Run the backtest\n",
        "    str_df, trade_df = backtest(days, p, orb_m, target_R, risk, max_Lev, AUM_0, commission)\n",
        "\n",
        "    # Save trade details\n",
        "    trade_df.to_csv('trade_details.csv', index=False)\n",
        "\n",
        "    # Performance analysis\n",
        "    returns = price2return(str_df['AUM'].values)\n",
        "\n",
        "    display(Markdown(\"### Performance Summary\"))\n",
        "    display(summary_statistics(returns))\n",
        "\n",
        "    display(Markdown(\"### Monthly Performance\"))\n",
        "    display(monthly_performance_table(returns, str_df['Date']))\n",
        "\n",
        "    # Plot equity curve\n",
        "    fig, ax = plot_equity_curve(str_df, AUM_0, orb_m, target_R, TICKER)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "LvjF8a2PM1LO",
        "outputId": "5c9a4b84-6837-478c-ea0f-18b187b72a9c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching daily adjusted data for ATR calculation...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "get_yfinance_data() got an unexpected keyword argument 'interval'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-6-2146913112.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;31m# Download & merge data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_and_merge_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data download failed.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-6-2146913112.py\u001b[0m in \u001b[0;36mdownload_and_merge_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;34m\"\"\"Download and merge intraday and daily data using Yahoo Finance.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;31m# Get daily data for ATR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mdaily_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_daily_adjusted_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdaily_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unable to get daily data. Exiting.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4-1710136072.py\u001b[0m in \u001b[0;36mget_daily_adjusted_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mATR_START_DATE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTART_DATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%Y-%m-%d'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y-%m-%d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mdaily_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_yfinance_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"1d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mATR_START_DATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdaily_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: get_yfinance_data() got an unexpected keyword argument 'interval'"
          ]
        }
      ]
    }
  ]
}